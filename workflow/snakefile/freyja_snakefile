import pandas as pd
import json

msg = "snakefile command recieved - FREYJA AND POST PROCESSING \n"
sys.stderr.write(msg)

ruleorder: freyja_demix > sample_freyja_vis > clean_up_fastqc_zip_pe > clean_up_fastqc_zip_se
### Define wildcards ###
pe_zpd_samples = glob_wildcards("staging/pe_reads/{sample}_R{read_num}.fastq.gz").sample
pe_unzpd_samples = glob_wildcards("staging/pe_reads/{sample}_R{read_num}.fastq").sample
se_zpd_samples = glob_wildcards("staging/se_reads/{sample}.fastq.gz").sample
se_unzpd_samples = glob_wildcards("staging/se_reads/{sample}.fastq").sample
samples = pe_zpd_samples+ pe_unzpd_samples + se_zpd_samples + se_unzpd_samples

### Define functions for global handelers: Onstart, onsuccess and onerror ###
# Define the onstart handler
def onstart(samples):
    print(f"Starting workflow for {wildcards}")
# Define the onsuccess handler
def onsuccess(samples):
    print(f"Workflow completed successfully for {wildcards}")


# Define the onerror handler
def onerror(wildcards, input, output, error):
    msg = f"Error occurred for {wildcards} \n \
    Input: {input} \n \
    Output: {output} \n \
    Error: {error}"
    with open("JobFailed.txt", "w") as failed_samples:
        print(msg)
    pass

### Define global handlers ###
onstart: onstart
onsuccess: onsuccess
onerror: onerror
configfile: "config.json"
workflow_dir = config["workflow_dir"]
### freyja variant variables ###
minimum_base_quality_score_val = config["params"]["minimum_base_quality_score"]
### freyja command variables ###
barcodes_path = config["barcodes_path"]
curated_lineages = config["curated_lineages_path"]
lineages = config["lineages_path"]
eps_val = config["params"]["minimum_lineage_abundance"]
covcut_val = config["params"]["coverage_estimate"]
depthcutoff_val = config["params"]["minimum_coverage_depth"]
if config["params"]["confirmedonly"] == True:
    confirmed_only_status = "--confirmedonly"
else:
    confirmed_only_status = ""
### freyja aggregate variables ###
minimum_genome_coverage_val = config["params"]["minimum_genome_coverage"]
### freyja plot variables ###
agg_minimum_lineage_abundance_val = config["params"]["agg_minimum_lineage_abundance"]

# Load the JSON data
with open("config.json") as f:
    data = json.load(f)
    # Extract data from single_end_libs with dates (ignore without dates)
    single_end_data = [(entry['sample_id'], entry['sample_level_date']) 
                   for entry in data['params']['single_end_libs'] 
                   if entry.get('sample_level_date') is not None]

    # Extract data from paired_end_libs with dates (ignore without dates)
    # paired_end_data = [(entry['sample_id'], entry.get('sample_level_date', None)) for entry in data['params']['paired_end_libs']]
    paired_end_data = [(entry['sample_id'], entry['sample_level_date']) 
                   for entry in data['params']['paired_end_libs'] 
                   if entry.get('sample_level_date') is not None]
    #Create DataFrame for single_end_libs
    single_end_df = pd.DataFrame(single_end_data, columns=['sample_id', 'sample_level_date'])
    # # Create DataFrame for paired_end_libs
    paired_end_df = pd.DataFrame(paired_end_data, columns=['sample_id', 'sample_level_date'])
    # Concatenate single_end_df and paired_end_df
    merged_df = pd.concat([single_end_df, paired_end_df], ignore_index=True)
    # ## prep date .CSV for Freyja plotting ##
    # Pull outonly the columns Freyja is expecting
    dates_df = merged_df[['sample_id', 'sample_level_date']]
    # Rename columns for the column names Freyja is expecting 
    dates_df.rename(columns={"sample_id":"Sample", "sample_level_date":"sample_collection_datetime"}, inplace = True)
    # # Add _freyja_variants.tsv to sample id as Freyja is expecting 
    variant_file_ext = '_freyja_variants.tsv'
    dates_df['Sample'] = dates_df['Sample'].astype(str) + variant_file_ext
    # Print date and sample information to csv for Freyja plotting command
    dates_df.to_csv("sample_time_metadata.csv", index=False)

# Define base rule all
rule_all_list = [
        expand("output/{sample}/freyja/{sample}_freyja_variants.tsv", sample=samples),
        expand("output/{sample}/freyja/{sample}_freyja_result.tsv", sample=samples),
        expand("output/{sample}/{sample}_variant_plot.svg", sample=samples),
        expand("assembly_images/{sample}.png", sample=samples)
    ]

### append clean up rule for fastQC zip to rule all depending on the paired reads vs single end reads ###
pe_samples = pe_zpd_samples + pe_unzpd_samples
se_samples = se_zpd_samples + se_unzpd_samples
if len(pe_samples) > 0:
        rule_all_list.append(expand("clean_up/{pe_sample}/fastqc_results/{pe_sample}_R1_fastqc.zip", pe_sample=pe_samples))
        rule_all_list.append(expand("clean_up/{pe_sample}/fastqc_results/{pe_sample}_R2_fastqc.zip", pe_sample=pe_samples))
if len(se_samples) >0:
    rule_all_list.append(expand("clean_up/{se_sample}/fastqc/{se_sample}_fastqc.zip", se_sample=se_samples))

rule all:
    input:
        rule_all_list

rule copy_assembly_images_for_report:
    input:
        assembly_image = "output/{sample}/assembly/{sample}.png"
    params:
        image_dir = "assembly_images"
    output:
        assembly_images = "assembly_images/{sample}.png"
    shell:
        """
        mkdir -p {params.image_dir}

        cp {input.assembly_image} {output.assembly_images}
        """
rule freyja_variants:
    input:
        ivar_bam_sorted = "output/{sample}/assembly/{sample}.sorted.bam",
        reference = "output/{sample}/assembly/reference_trimmed.fa",
    params:
        eps = eps_val,
        freyja_analysis_dir = directory("output/{sample}"),
        minimum_base_quality_score = minimum_base_quality_score_val,
        tmp_dir = directory("./tmp/")
    output:
        variants = "output/{sample}/freyja/{sample}_freyja_variants.tsv",
        depth = "output/{sample}/freyja/{sample}_freyja.depths",
    shell:
        """
        mkdir -p {params.freyja_analysis_dir}

        freyja variants \
            {input.ivar_bam_sorted} \
            --minq {params.minimum_base_quality_score} \
            --variants {output.variants} \
            --depths {output.depth} \
            --ref {input.reference}
        """

rule freyja_demix:
    input:
        barcodes = barcodes_path,
        curated_lineages_ = curated_lineages,
        variants = "output/{sample}/freyja/{sample}_freyja_variants.tsv",
        depth = "output/{sample}/freyja/{sample}_freyja.depths",
    params:
        eps = eps_val,
        covcut = covcut_val,
        confirmedonly = confirmed_only_status,
        depthcutoff = depthcutoff_val,
        tmp_dir = directory("tmp/"),
        error_msg = "tmp/{sample}_demix_error.txt"
    output:
        freyja_file = "output/{sample}/freyja/{sample}_freyja_result.tsv",
        tmp_freyja = "tmp/{sample}_freyja_result.tsv"
    shell:
        """
        mkdir -p {params.tmp_dir}

        freyja demix \
            --eps {params.eps} \
            --barcodes {input.barcodes} \
            --meta {input.curated_lineages_} \
            --covcut {params.covcut} \
            --output {output.freyja_file} {params.confirmedonly} \
            --depthcutoff {params.depthcutoff} \
            {input.variants} \
            {input.depth} \
            > {params.error_msg}

        cp {output.freyja_file} {output.tmp_freyja}
        """

rule sample_freyja_vis:
    input:
        # Freyja aggregate command expects a directory not the demixing results files themselves
        # adding the demxing results to help multi threading track the order
        freyja_file = "output/{sample}/freyja/{sample}_freyja_result.tsv",
	tmp_freyja_file = "tmp/{sample}_freyja_result.tsv"
    params:
        freyja_dir = directory("output/{sample}/freyja/"),
        cl_agg_dir = directory("clean_up/single_aggs/{sample}"),
        lineage_yml = lineages,
        single_aggregate = "output/{sample}/{sample}_aggregated_result.tsv",
        ext = "_freyja_result.tsv",
        minimum_genome_coverage = minimum_genome_coverage_val,
        agg_minimum_lineage_abundance = agg_minimum_lineage_abundance_val,
        variant_plot_msg = "tmp/{sample}_sample_variant_plot_error.txt",
        lineage_plot_msg = "tmp/{sample}_sample_lineage_plot_error.txt"
    output:
        plot = "output/{sample}/{sample}_variant_plot.svg",
        lineage_plot = "output/{sample}/{sample}_lineage_plot.svg",
        clean_single_aggregate = "clean_up/single_aggs/{sample}/{sample}_aggregated_result.tsv",
    shell:
        """
        freyja aggregate \
            {params.freyja_dir} \
            --ext {params.ext} \
            --output {params.single_aggregate}

        freyja plot \
            {params.single_aggregate} \
            --lineageyml {params.lineage_yml} \
            --mincov {params.minimum_genome_coverage} \
            --thresh {params.agg_minimum_lineage_abundance} \
            --output {output.plot} > {params.variant_plot_msg}

        freyja plot \
            {params.single_aggregate} \
            --lineages \
            --lineageyml {params.lineage_yml} \
            --mincov {params.minimum_genome_coverage} \
            --thresh {params.agg_minimum_lineage_abundance} \
            --output {output.lineage_plot} > {params.lineage_plot_msg}
        
        # the single aggregate file is redundant to the freyja file. Moving to clean up directory
        mkdir -p {params.cl_agg_dir}

        mv {params.single_aggregate} {output.clean_single_aggregate}
        """

rule clean_up_fastqc_zip_se:
    input:
        zip_path = "output/{se_sample}/fastqc_results/{se_sample}_fastqc.zip",
        ivar_zip_path = "output/{se_sample}/fastqc_results/{se_sample}.ivar_fastqc.zip",
        sorted_zip_path = "output/{se_sample}/fastqc_results/{se_sample}.sorted_fastqc.zip",
    params:
        cl_agg_dir = directory("clean_up/fastqc/{se_sample}")
    output:
        clean_zip = "clean_up/{se_sample}/fastqc/{se_sample}_fastqc.zip",
        clean_ivar_zip_path = "clean_up/{se_sample}/fastqc/{se_sample}.ivar_fastqc.zip",
        clean_sorted_zip_path = "clean_up/{se_sample}/fastqc/{se_sample}.sorted_fastqc.zip",
    shell:
        """
        mkdir -p {params.cl_agg_dir}

        mv {input.zip_path} {output.clean_zip}
        mv {input.ivar_zip_path} {output.clean_ivar_zip_path}
        mv {input.sorted_zip_path} {output.clean_sorted_zip_path}
        """

rule clean_up_fastqc_zip_pe:
    input:
        zip_path_R1 = "output/{pe_sample}/fastqc_results/{pe_sample}_R1_fastqc.zip",
        zip_path_R2 = "output/{pe_sample}/fastqc_results/{pe_sample}_R2_fastqc.zip",
        ivar_zip_path = "output/{pe_sample}/fastqc_results/{pe_sample}.ivar_fastqc.zip",
        sorted_zip_path = "output/{pe_sample}/fastqc_results/{pe_sample}.sorted_fastqc.zip",
    params:
        cl_agg_dir = directory("clean_up/{pe_sample}/fastqc_results/")
    output:
        clean_zip_R1 = "clean_up/{pe_sample}/fastqc_results/{pe_sample}_R1_fastqc.zip",
        clean_zip_R2 = "clean_up/{pe_sample}/fastqc_results/{pe_sample}_R2_fastqc.zip",
        clean_ivar_zip_path = "clean_up/{pe_sample}/fastqc_results/{pe_sample}.ivar_fastqc.zip",
        clean_sorted_zip_path = "clean_up/{pe_sample}/fastqc_results/{pe_sample}.sorted_fastqc.zip",
    shell:
        """
        mkdir -p {params.cl_agg_dir}

        mv {input.zip_path_R1} {output.clean_zip_R1}
        mv {input.zip_path_R2} {output.clean_zip_R2}
        mv {input.ivar_zip_path} {output.clean_ivar_zip_path}
        mv {input.sorted_zip_path} {output.clean_sorted_zip_path}
        """
