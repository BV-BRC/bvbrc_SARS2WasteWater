msg = "snakefile command recieved - STATS/Wrap up \n"
sys.stderr.write(msg)

# ruleorder: freyja_variants > freyja_demix > sample_freyja_vis
### Define wildcards ###
pe_zpd_samples = glob_wildcards("staging/pe_reads/{sample}_R{read_num}.fastq.gz").sample
pe_unzpd_samples = glob_wildcards("staging/pe_reads/{sample}_R{read_num}.fastq").sample
se_zpd_samples = glob_wildcards("staging/se_reads/{sample}.fastq.gz").sample
se_unzpd_samples = glob_wildcards("staging/se_reads/{sample}.fastq").sample
samples = pe_zpd_samples+ pe_unzpd_samples + se_zpd_samples + se_unzpd_samples

### Define functions for global handelers: Onstart, onsuccess and onerror ###
# Define the onstart handler
def onstart(samples):
    print(f"Starting workflow for {wildcards}")
# Define the onsuccess handler
def onsuccess(samples):
    print(f"Workflow completed successfully for {wildcards}")


# Define the onerror handler
def onerror(wildcards, input, output, error):
    msg = f"Error occurred for {wildcards} \n \
    Input: {input} \n \
    Output: {output} \n \
    Error: {error}"
    with open("JobFailed.txt", "w") as failed_samples:
        print(msg)
    pass

### Define global handlers ###
onstart: onstart
onsuccess: onsuccess
onerror: onerror
### freyja command variables ###
configfile: "config.json"
workflow_dir = config["workflow_dir"]
barcodes_path = config["barcodes_path"]
curated_lineages = config["curated_lineages_path"]
lineages = config["lineages_path"]
last_barcode_update = config["last_barcode_update"]
### freyja aggregate variables ###
minimum_genome_coverage_val = config["params"]["minimum_genome_coverage"]
### freyja plot variables ###
agg_minimum_lineage_abundance_val = config["params"]["agg_minimum_lineage_abundance"]
### version long variables ###
primer_type = config["params"]["primers"]
primer_version = config["params"]["primer_version"]


rule_all_list = [
        "output/multiqc_report.html",
        "output/version_log.txt",
        "output/freyja_result.tsv",
        "plots/variants_plot.html",
        "plots/lineages_plot.html"
]
# If dates are passed, check if metadata.csv is exists then make the time series plots
if os.path.exists("sample_time_metadata.csv"):
    time_metadata_csv = "sample_time_metadata.csv"
    # add time series plot to rule all
    rule_all_list.append("plots/variants_by_month_plot.html")
    rule_all_list.append("plots/lineages_by_month_plot.html")

rule all:
    input:
        rule_all_list

rule set_aggregate_command:
    input:
        # Freyja aggregate command expects a directory not the files themselves
        # Using the tmp message file incase a sample files to stil populate even if some samples fail
        # Using set to ensure all files try to run demix. Then use any availble demix results.
        # set_tmp_msg_file = set(expand("output/{sample}/{sample}_demixing_result.csv", sample=samples))
    params:
        # for snakemake the directory needs to end with "/"
        tmp_dir = directory("tmp/"),
        ext = "_freyja_result.tsv ",
    output:
        aggregated = "output/freyja_result.tsv",
    shell:
        """
        freyja aggregate \
            {params.tmp_dir} \
            --ext {params.ext} \
            --output {output.aggregated}
        """

rule set_freyja_vis:
    input:
        # Using the tmp message file incase a sample files to stil populate even if some samples fail
        # Using set to ensure all files try to run demix. Then use any availble demix results.
        aggregated = "output/freyja_result.tsv"
    params:
        sample_plots_script = os.path.join(workflow_dir, "scripts/sample_level_plots.py")
    output:
        lineage_plot = "plots/lineages_plot.html",
        variant_plot = "plots/variants_plot.html",
    shell:
        """
    python3 {params.sample_plots_script} \
        {input.aggregated} \
        {output.lineage_plot} \
        {output.variant_plot}
        """

rule set_timeseries_plot:
    input:
        aggregated = "output/freyja_result.tsv",
    params:
        metadata_csv = time_metadata_csv,
        edited_metadata_csv = "edited_sample_time_metadata.csv",
        edit_time_metadata = os.path.join(workflow_dir, "scripts/edit_time_metadata_csv.py"),
        plot_timedata = os.path.join(workflow_dir, "scripts/time_series_plots.py"),
        plots_dir = directory('plots'),
    output:
        variants_day_plot = "plots/variants_by_day_plot.html",
        variants_week_plot = "plots/variants_by_week_plot.html",
        variants_month_plot = "plots/variants_by_month_plot.html",
        lineages_day_plot = "plots/lineages_by_day_plot.html",
        lineages_week_plot = "plots/lineages_by_week_plot.html",
        lineages_month_plot = "plots/lineages_by_month_plot.html"
    shell:
        """
    mkdir -p {params.plots_dir}

    python3 {params.edit_time_metadata}

    python3 {params.plot_timedata} \
        {input.aggregated} \
        edited_sample_time_metadata.csv \
        {output.lineages_day_plot} \
        {output.variants_day_plot} \
        {output.lineages_week_plot} \
        {output.variants_week_plot} \
        {output.lineages_month_plot} \
        {output.variants_month_plot}
        """

rule multiqc:
    input:
       multiqc_config = os.path.join(workflow_dir, "multiqc_config.yaml"),
    params:
        landing_dir = directory('output'),
        tmp_multiqc_dir = directory('output/multiqc_data')
    output:
        'output/multiqc_report.html',
        cl_multiqc_dir = directory("clean_up/multiqc_data")
    shell:
        """
        multiqc --version

        multiqc clean_up/. output/. \
            -c {input.multiqc_config} \
            -o {params.landing_dir} --fullnames \
            -f
        
        mkdir -p {output.cl_multiqc_dir}

        mv {params.tmp_multiqc_dir} {output.cl_multiqc_dir}
        """

rule write_out_versions:
    params:
        primer_tp = primer_type,
        primer_v = primer_version,
        last_barcode_update_file = last_barcode_update
    output: 
        version_log = "output/version_log.txt",
        barcode_version = "barcode_version.txt"
    shell:
        """
        echo "The results may vary depending on the version of Freyja, its dependences and the barcode file used. The barcode file is a .tsv file that is used in lineage-determination defined by the UShER global phylogenetic tree. We update the barcodes every two weeks.\n Below are the versions of the tools used in this analysis. \n" >> {output.version_log}

        echo "primer type: {params.primer_tp}" >> {output.version_log}

        echo "primer version: {params.primer_v}" >> {output.version_log}
        freyja --version >> {output.version_log}

        echo "Barcode version:" >> {output.version_log}

        cat {params.last_barcode_update_file} >> {output.version_log}

        ivar version >> {output.version_log}

        samtools version >> {output.version_log}

        cat {params.last_barcode_update_file} >> {output.barcode_version}
        """